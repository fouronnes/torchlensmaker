{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46bf6f-a462-4ca8-bcaf-b926f57364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchlensmaker as tlm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# update all shapes to new share / init way\n",
    "# implement non shape parameter to see if archi still works - ex: VariableGap\n",
    "\n",
    "# nice gap syntax\n",
    "# rework all examples / tests\n",
    "\n",
    "# either: per parameter learning rate adapted to its scale\n",
    "# or: all internal parameters in same scale / units to work well with a common learning rate\n",
    "\n",
    "class tlmModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom nn.Module to automatically register parameters of shapes\n",
    "\n",
    "    This is similar to how PyTorch's nn.Module automatically registers nn.Parameters\n",
    "    that are assigned to it. But here, we register tlm shapes and their inner parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        super().__setattr__(\"_shapes\", {})\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        if name in self.__dict__[\"_shapes\"]:\n",
    "            return self.__dict__[\"_shapes\"][name]\n",
    "        else:\n",
    "            return super().__getattr__(name)\n",
    "    \n",
    "    def __setattr__(self, name: str, value):\n",
    "        if isinstance(value, tlm.Parabola):\n",
    "            for parameter_name, parameter in value.parameters().items():\n",
    "                # TODO add shape name/id\n",
    "                self.register_parameter(name + \"_\" + parameter_name, parameter)\n",
    "            self.__dict__[\"_shapes\"][name] = value\n",
    "        else:\n",
    "            super().__setattr__(name, value)\n",
    "\n",
    "\n",
    "class DevStack(tlmModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # optimizable\n",
    "        self.shape1 = tlm.Parabola(width = 20., a = nn.Parameter(torch.tensor(0.005)))\n",
    "\n",
    "        # share from other shape\n",
    "        #self.shape2 = self.shape1.flip()\n",
    "\n",
    "        # fixed value\n",
    "        self.shape2 = tlm.Parabola(width = 20., a = -0.005)\n",
    "\n",
    "        # free parameter\n",
    "        self.x = nn.Parameter(torch.tensor(5.0))\n",
    "\n",
    "        #self.x = tlm.Parameter(torch.tensor(5.0), learning_scale=10)\n",
    "\n",
    "    # TODO improve hook situation\n",
    "    def forward(self, num_rays):\n",
    "        surface1 = tlm.Surface(self.shape1, pos=(0, 0), anchor=\"origin\")\n",
    "        surface2 = tlm.Surface(self.shape2, pos=surface1.at(\"extent\") + torch.tensor([0, 1]), anchor=\"extent\")\n",
    "\n",
    "        offset = torch.stack((self.x, torch.tensor(10)))\n",
    "        surface3 = tlm.Surface(self.shape1, pos=surface2.at(\"origin\") + offset, anchor=\"origin\")\n",
    "        surface4 = tlm.Surface(self.shape2, pos=surface3.at(\"extent\") + torch.tensor([0, 1]), anchor=\"extent\")\n",
    "\n",
    "        ##\n",
    "        #self.surface1.move((0, 0), \"origin\")\n",
    "        #self.surface2.move_extent(surface1.extent() + torch.tensor([0, 1]))\n",
    "\n",
    "        # idea: share shapes by contructing multiple surfaces with the same shape instead of cloning shapes\n",
    "        #s1 = tlm.Surface(self.shape1,  scale = -1, pos = (0, 0), anchor = \"origin\")\n",
    "\n",
    "        #self.S1.move(pos = (0, 0), anchor = \"origin\")\n",
    "\n",
    "        # init:\n",
    "        # self.S1 = Surface(..)\n",
    "\n",
    "        # forward:\n",
    "        # self.S1.move_origin( self.S2.origin() + torch.tensor([0, 10]) )        \n",
    "        # move_extent\n",
    "\n",
    "        \"\"\"\n",
    "        RefractiveSurface(shape1, scale=-1, anchors=(\"origin\", \"extent\"))\n",
    "        Gap((0, 5))\n",
    "\n",
    "        AbsolutePosition((6.0, 5.0))\n",
    "        RelativePosition(target=surfaceXX, offset=(...))\n",
    "        \n",
    "        ReflectiveSurface(...)\n",
    "        VariableGap(init=0.25, min=0.0, max=5.0)\n",
    "        ReflectiveSurface(...)\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        ParallelBeamUniform()\n",
    "        Gap()\n",
    "        RefractiveSurface()\n",
    "\n",
    "        inputs: (rays, target)\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # idea: add \"current\" position information in the data\n",
    "        # like we had implicitly when relative positioning\n",
    "        \n",
    "        self.optics = nn.Sequential(\n",
    "            tlm.ParallelBeamUniform(width=15., pos=(0, -10)),\n",
    "        \n",
    "            tlm.RefractiveSurface(surface1, (1.0, 1.49)),\n",
    "            tlm.RefractiveSurface(surface2, (1.49, 1.0)),\n",
    "        \n",
    "            tlm.RefractiveSurface(surface3, (1.0, 1.49)),\n",
    "            tlm.RefractiveSurface(surface4, (1.49, 1.0)),\n",
    "        \n",
    "            tlm.FocalPointLoss(pos=(0, 80)),\n",
    "        )\n",
    "        \n",
    "\n",
    "        return self.optics(num_rays)\n",
    "\n",
    "optics = DevStack()\n",
    "\n",
    "for n, p in optics.named_parameters():\n",
    "    print(n, p)\n",
    "\n",
    "tlm.render_plt(optics, 10)\n",
    "\n",
    "tlm.optimize(\n",
    "    optics,\n",
    "    optimizer = optim.Adam(optics.parameters(), lr=1e-2),\n",
    "    num_rays = 20,\n",
    "    num_iter = 50,\n",
    ")\n",
    "\n",
    "tlm.render_plt(optics, 10)\n",
    "\n",
    "# signal what I want to optimize or not by just wrapping into parameter:\n",
    "\n",
    "# ReflectiveSurface(Parabola(tlm.Parameter(5.0)))\n",
    "# vs\n",
    "# ReflectiveSurface(Parabola(5.0), pos=(a, b))\n",
    "\n",
    "# setup a linear stack with same syntax gap(), etc.\n",
    "# but preprocess the stack to remove gaps and setup surfaces origins/anchors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8251a94-fe0e-4f3f-918f-1b3da3be42fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
