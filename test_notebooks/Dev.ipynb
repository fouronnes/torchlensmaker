{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46bf6f-a462-4ca8-bcaf-b926f57364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchlensmaker as tlm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# sharing at the surface level rather than shape level\n",
    "\n",
    "# update all shapes to new share / init way\n",
    "# absolute positioning on X\n",
    "# rework all examples / tests\n",
    "\n",
    "# either: per parameter learning rate adapted to its scale\n",
    "# or: all internal parameters in same scale / units to work well with a common learning rate\n",
    "\n",
    "class tlmModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom nn.Module to automatically register parameters of shapes\n",
    "\n",
    "    This is similar to how PyTorch's nn.Module automatically registers nn.Parameters\n",
    "    that are assigned to it. But here, we register tlm shapes and their inner parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        super().__setattr__(\"_shapes\", {})\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        if name in self.__dict__[\"_shapes\"]:\n",
    "            return self.__dict__[\"_shapes\"][name]\n",
    "        else:\n",
    "            return super().__getattr__(name)\n",
    "    \n",
    "    def __setattr__(self, name: str, value):\n",
    "        if isinstance(value, tlm.Parabola):\n",
    "            for parameter_name, parameter in value.parameters().items():\n",
    "                # TODO add shape name/id\n",
    "                self.register_parameter(name + \"_\" + parameter_name, parameter)\n",
    "            self.__dict__[\"_shapes\"][name] = value\n",
    "        else:\n",
    "            super().__setattr__(name, value)\n",
    "\n",
    "\"\"\"\n",
    "        RefractiveSurface(shape1, scale=-1, anchors=(\"origin\", \"extent\"))\n",
    "        Gap((0, 5))\n",
    "\n",
    "        AbsolutePosition((6.0, 5.0))\n",
    "        RelativePosition(target=surfaceXX, offset=(...))\n",
    "        \n",
    "        ReflectiveSurface(...)\n",
    "        VariableGap(init=0.25, min=0.0, max=5.0)\n",
    "        ReflectiveSurface(...)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class DevStack(tlmModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # optimizable\n",
    "        self.shape1 = tlm.Parabola(width = 20., a = nn.Parameter(torch.tensor(0.005)))\n",
    "\n",
    "        # share from other shape\n",
    "        #self.shape2 = self.shape1.flip()\n",
    "\n",
    "        # fixed value\n",
    "        #self.shape2 = tlm.Parabola(width = 20., a = -0.005)\n",
    "\n",
    "        # free parameter\n",
    "        self.x = nn.Parameter(torch.tensor(5.0))\n",
    "\n",
    "        #self.x = tlm.Parameter(torch.tensor(5.0), learning_scale=10)\n",
    "\n",
    "        self.optics = nn.Sequential(\n",
    "            tlm.ParallelBeamUniform(width=15.),\n",
    "            tlm.Gap(torch.tensor([0, 10])),\n",
    "        \n",
    "            tlm.RefractiveSurface(self.shape1, (1.0, 1.49), anchors=(\"origin\", \"extent\")),\n",
    "            tlm.Gap(torch.tensor([0, 1])),\n",
    "            tlm.RefractiveSurface(self.shape1, (1.49, 1.0), scale=-1., anchors=(\"extent\", \"origin\")),\n",
    "\n",
    "            tlm.Gap(torch.tensor([0, 80])),\n",
    "        \n",
    "            tlm.FocalPointLoss(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.optics(inputs)\n",
    "\n",
    "\n",
    "optics = DevStack()\n",
    "\n",
    "print(\"Parameters\")\n",
    "for n, p in optics.named_parameters():\n",
    "    print(n, p.detach().numpy())\n",
    "print()\n",
    "\n",
    "tlm.render_plt(optics, (10, torch.tensor([0., 0.])))\n",
    "\n",
    "tlm.optimize(\n",
    "    optics,\n",
    "    optimizer = optim.Adam(optics.parameters(), lr=1e-2),\n",
    "    inputs = (10, torch.tensor([0., 0.])),\n",
    "    num_iter = 500,\n",
    ")\n",
    "\n",
    "tlm.render_plt(optics, (10, torch.tensor([0., 0.])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8251a94-fe0e-4f3f-918f-1b3da3be42fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
